import { useRef, useCallback } from 'react';
import { GoogleGenAI } from '@google/genai';

interface TranscriptEntry {
  speaker: string;
  text: string;
  timestamp: Date;
  turnId: string;
}

interface QualificationLogEntry {
  timestamp: Date;
  field: string;
  oldValue: any;
  newValue: any;
  source: 'user' | 'ai' | 'system';
  confidence: 'high' | 'medium' | 'low';
}

export const useGeminiQualificationProcessor = (apiKey?: string) => {
  const geminiRef = useRef<GoogleGenAI | null>(null);
  const conversationHistoryRef = useRef<TranscriptEntry[]>([]);

  // Initialize Gemini when API key is available
  const initializeGemini = useCallback(() => {
    if (apiKey && !geminiRef.current) {
      geminiRef.current = new GoogleGenAI({ apiKey });
      console.log("âœ… Gemini qualification processor initialized");
    }
  }, [apiKey]);

  const processQualificationData = useCallback(async (
    newEntry: TranscriptEntry,
    currentData: any,
    updateData: (data: any) => void,
    addLogEntry: (entry: QualificationLogEntry) => void
  ) => {
    initializeGemini();
    
    if (!geminiRef.current) {
      console.log("âŒ Gemini not initialized for qualification processing");
      return;
    }

    // Add to conversation history
    conversationHistoryRef.current.push(newEntry);
    
    // Keep only recent conversation (last 20 entries)
    if (conversationHistoryRef.current.length > 20) {
      conversationHistoryRef.current = conversationHistoryRef.current.slice(-20);
    }

    try {
      // Build conversation context
      const conversationContext = conversationHistoryRef.current
        .map(entry => `${entry.speaker}: ${entry.text}`)
        .join('\n');

      console.log("ðŸ” Processing qualification with context:", {
        newEntry: `${newEntry.speaker}: ${newEntry.text}`,
        turnId: newEntry.turnId,
        historyLength: conversationHistoryRef.current.length
      });

      const model = geminiRef.current.models.generateContent({
        model: 'gemini-2.5-flash-preview-05-20',
        config: {
          temperature: 0.1,
          responseMimeType: 'application/json'
        },
        contents: [{
          role: 'user',
          parts: [{
            text: `VocÃª Ã© um especialista em extraÃ§Ã£o de dados de qualificaÃ§Ã£o de leads para a G4 EducaÃ§Ã£o.

CONTEXTO DA CONVERSA COMPLETA:
${conversationContext}

DADOS ATUAIS:
${JSON.stringify(currentData, null, 2)}

TAREFA:
Analise TODA a conversa acima e extraia/atualize as informaÃ§Ãµes de qualificaÃ§Ã£o. Use tanto as falas da Mari quanto do usuÃ¡rio para inferir as respostas corretas.

REGRAS IMPORTANTES:
1. Use TODA a conversa para inferir informaÃ§Ãµes, nÃ£o apenas a Ãºltima mensagem
2. Mari frequentemente confirma ou repete informaÃ§Ãµes - use isso para validar dados
3. Se houver conflito, prefira a informaÃ§Ã£o mais recente ou confirmada por Mari
4. Mantenha dados existentes se nÃ£o houver novas informaÃ§Ãµes
5. Seja inferencial - por exemplo, "acompanho os conteÃºdos no Instagram" = "Instagram"

CAMPOS OBRIGATÃ“RIOS:
- nome_completo: Nome completo da pessoa
- nome_empresa: Nome da empresa
- como_conheceu_g4: Como conheceu (Instagram, indicaÃ§Ã£o, Google, etc.)
- faturamento_anual_aproximado: Faturamento da empresa (formato: R$ X.XXX.XXX)
- total_funcionarios_empresa: NÃºmero de funcionÃ¡rios (nÃºmero inteiro)
- setor_empresa: Setor de atuaÃ§Ã£o
- principal_desafio: Principal desafio da empresa
- melhor_dia_contato_especialista: Melhor dia para contato
- melhor_horario_contato_especialista: Melhor horÃ¡rio
- preferencia_contato_especialista: "Ligacao" ou "WhatsApp"
- telefone: NÃºmero de telefone
- qualificador_nome: "Mari"

Retorne APENAS um JSON com os campos que foram identificados/atualizados na conversa. NÃƒO inclua campos vazios ou null.

Exemplo de resposta:
{
  "nome_completo": "JoÃ£o VÃ­tor Silva",
  "como_conheceu_g4": "Instagram",
  "total_funcionarios_empresa": 80,
  "principal_desafio": "turnover da equipe"
}`
          }]
        }]
      });

      const response = await model;
      const responseText = response.text?.trim();
      
      console.log("ðŸ¤– Gemini qualification response:", responseText);

      if (responseText) {
        try {
          const extractedData = JSON.parse(responseText);
          
          if (extractedData && typeof extractedData === 'object') {
            // Process each extracted field
            Object.entries(extractedData).forEach(([field, value]) => {
              if (value !== null && value !== undefined && value !== '') {
                const oldValue = currentData[field];
                
                // Only update if value is different
                if (oldValue !== value) {
                  console.log(`ðŸ“Š Updating field: ${field} = ${value}`);
                  
                  addLogEntry({
                    timestamp: new Date(),
                    field,
                    oldValue,
                    newValue: value,
                    source: newEntry.speaker === 'Mari' ? 'ai' : 'user',
                    confidence: 'high'
                  });
                }
              }
            });
            
            // Update the qualification data
            updateData(extractedData);
          }
        } catch (parseError) {
          console.error("âŒ Error parsing qualification response:", parseError);
        }
      }
    } catch (error) {
      console.error("âŒ Error processing qualification data:", error);
    }
  }, [initializeGemini]);

  const resetProcessor = useCallback(() => {
    conversationHistoryRef.current = [];
    console.log("ðŸ”„ Qualification processor reset");
  }, []);

  return {
    processQualificationData,
    resetProcessor
  };
};
